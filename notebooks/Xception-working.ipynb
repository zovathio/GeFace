{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chdir. it depends on the platform\n",
    "if sys.platform == 'linux':\n",
    "    # if os is linux cd to\n",
    "    project_path = \"/home/mate/develop/PycharmProjects/GeFace/\"\n",
    "    NUMBER_OF_DATA = 100000\n",
    "elif sys.platform is 'windows':\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mate/develop/PycharmProjects/GeFace\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(os.getcwd())\n",
    "    # Open CSV with all informations\n",
    "    csv_file = pd.read_csv(\"faces_colored/faces_correct.csv\",delimiter = ',', encoding = \"ISO-8859-1\", engine='python')\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "except (FileNotFoundError):\n",
    "    print(\"CSV file not found\")\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current path is \" + current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr  age                                     full_path  gender\n",
       "0   0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg     1.0\n",
       "1   1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg     1.0\n",
       "2   2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg     1.0\n",
       "3   5   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg     0.0\n",
       "4   6   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = csv_file.drop(columns=[\"nr\"])\n",
    "df = csv_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 1.0 to m as male\n",
    "#         0.0 to f as female\n",
    "def mod(x):\n",
    "    if x == 1.0:\n",
    "        x = \"m\"\n",
    "    else:\n",
    "        x = \"f\"\n",
    "    return x\n",
    "\n",
    "df[\"gender\"] = df[\"gender\"].apply(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr  age                                     full_path gender\n",
       "0   0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg      m\n",
       "1   1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg      m\n",
       "2   2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg      m\n",
       "3   5   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg      f\n",
       "4   6   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg      f"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for testing the network\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "proba_df = df.head(NUMBER_OF_DATA)\n",
    "\n",
    "# Randomize but always the same random numbers\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# shuffle rows\n",
    "proba_df = shuffle(proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75721</th>\n",
       "      <td>132525</td>\n",
       "      <td>40</td>\n",
       "      <td>65/nm0001865_rm831429376_1962-9-12_2002.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80184</th>\n",
       "      <td>140033</td>\n",
       "      <td>75</td>\n",
       "      <td>96/nm0004696_rm451644672_1930-1-20_2005.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>34616</td>\n",
       "      <td>38</td>\n",
       "      <td>29/nm0000229_rm1636994304_1946-12-18_1984.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76699</th>\n",
       "      <td>134240</td>\n",
       "      <td>43</td>\n",
       "      <td>36/nm0002036_rm3676407296_1926-5-5_1969.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92991</th>\n",
       "      <td>161366</td>\n",
       "      <td>32</td>\n",
       "      <td>37/nm0005137_rm2106622976_1961-4-18_1993.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nr  age                                      full_path gender\n",
       "75721  132525   40    65/nm0001865_rm831429376_1962-9-12_2002.jpg      f\n",
       "80184  140033   75    96/nm0004696_rm451644672_1930-1-20_2005.jpg      m\n",
       "19864   34616   38  29/nm0000229_rm1636994304_1946-12-18_1984.jpg      m\n",
       "76699  134240   43    36/nm0002036_rm3676407296_1926-5-5_1969.jpg      f\n",
       "92991  161366   32   37/nm0005137_rm2106622976_1961-4-18_1993.jpg      f"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 70000 | valid: 20000 | test: 10000\n"
     ]
    }
   ],
   "source": [
    "# calculate test train valid data numbers\n",
    "test_num = int(np.floor(0.1 * proba_df.shape[0]))\n",
    "valid_num = int(np.floor(0.2 * proba_df.shape[0]))\n",
    "train_num = int(proba_df.shape[0] - test_num - valid_num)\n",
    "print(\"train: {} | valid: {} | test: {}\".format(train_num, valid_num, test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (70000, 4) | valid: (20000, 4) | test: (10000, 4)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train valid and test data\n",
    "train_data = proba_df.iloc[0:train_num, :]\n",
    "\n",
    "valid_data = proba_df.iloc[train_num:train_num + valid_num, :]\n",
    "\n",
    "test_data = proba_df.iloc[ train_num+valid_num:, :]\n",
    "\n",
    "print(\"train: {} | valid: {} | test: {}\".format(train_data.shape, valid_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faces_colored/68/nm0000668_rm3273231872_1959-4-15_1995.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"faces_colored/\"\n",
    "x_train_p = image_path + train_data['full_path'].values\n",
    "x_valid_p = image_path + valid_data['full_path'].values\n",
    "x_test_p = image_path + test_data['full_path'].values\n",
    "\n",
    "# x_train_l = image_path + train_data['age'].values\n",
    "# x_valid_l = image_path + train_data['age'].values\n",
    "# x_test_l = image_path + train_data['age'].values\n",
    "\n",
    "x_test_p.shape\n",
    "x_test_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 70000  |  20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([40, 75, 38, ..., 40, 32, 42])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the ages\n",
    "y_train_age = train_data['age'].values\n",
    "y_valid_age = valid_data['age'].values\n",
    "y_test_age = test_data['age'].values\n",
    "\n",
    "print(\"age:\" ,len(y_train_age), \" | \", len(y_valid_age))\n",
    "y_train_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: 70000  |  20000\n"
     ]
    }
   ],
   "source": [
    "y_train_gender = train_data['gender'].values\n",
    "y_valid_gender = valid_data['gender'].values\n",
    "y_test_gender = test_data['gender'].values\n",
    "print(\"gender:\", len(y_train_gender), \" | \", len(y_valid_gender))\n",
    "\n",
    "# convert to string\n",
    "y_train_age = y_train_age.astype(\"str\")\n",
    "y_valid_age = y_valid_age.astype(\"str\")\n",
    "y_test_age = y_test_age.astype(\"str\")\n",
    "\n",
    "#concate them\n",
    "# y_train_gen_age = np.core.defchararray.add(y_train_age, y_train_gender)\n",
    "# y_valid_gen_age = np.core.defchararray.add(y_valid_age, y_valid_gender)\n",
    "# y_test_gen_age = np.core.defchararray.add(y_test_age, y_test_gender)\n",
    "\n",
    "# print(\"gen_age:\", len(y_train_gen_age), \" | \", len(y_valid_gen_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy train, valid, test data into a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75721</th>\n",
       "      <td>132525</td>\n",
       "      <td>40</td>\n",
       "      <td>65/nm0001865_rm831429376_1962-9-12_2002.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80184</th>\n",
       "      <td>140033</td>\n",
       "      <td>75</td>\n",
       "      <td>96/nm0004696_rm451644672_1930-1-20_2005.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>34616</td>\n",
       "      <td>38</td>\n",
       "      <td>29/nm0000229_rm1636994304_1946-12-18_1984.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76699</th>\n",
       "      <td>134240</td>\n",
       "      <td>43</td>\n",
       "      <td>36/nm0002036_rm3676407296_1926-5-5_1969.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92991</th>\n",
       "      <td>161366</td>\n",
       "      <td>32</td>\n",
       "      <td>37/nm0005137_rm2106622976_1961-4-18_1993.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nr  age                                      full_path gender\n",
       "75721  132525   40    65/nm0001865_rm831429376_1962-9-12_2002.jpg      f\n",
       "80184  140033   75    96/nm0004696_rm451644672_1930-1-20_2005.jpg      m\n",
       "19864   34616   38  29/nm0000229_rm1636994304_1946-12-18_1984.jpg      m\n",
       "76699  134240   43    36/nm0002036_rm3676407296_1926-5-5_1969.jpg      f\n",
       "92991  161366   32   37/nm0005137_rm2106622976_1961-4-18_1993.jpg      f"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from shutil import copyfile, copy2\n",
    "# try:\n",
    "#     os.mkdir(\"test_face\")\n",
    "# except FileExistsError:\n",
    "#     print(\"test_face Direcotry exist\")\n",
    "    \n",
    "# # training \n",
    "# try:\n",
    "#     os.mkdir(\"train_face\")\n",
    "#     # create directory structure\n",
    "    \n",
    "    \n",
    "# except FileExistsError:\n",
    "#     print(\"train_face Direcotry exist\")\n",
    "    \n",
    "# for i in range(100):\n",
    "#     try:\n",
    "#         if i < 10:\n",
    "        \n",
    "#             os.mkdir(\"train_face/0\" + str(i))\n",
    "#         else:\n",
    "#             os.mkdir(\"train_face/\" + str(i))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "# i = 0\n",
    "# dest_path = \"train_face/\"+train_data['full_path'].values\n",
    "# for p in x_train_p:\n",
    "    \n",
    "#     copy2(p, dest_path[i])\n",
    "#     i += 1\n",
    "# #     print(\"train_face/\"+train_data['full_path'].values)\n",
    "# #     print(dest_path[i])\n",
    "\n",
    "# # validation\n",
    "# try:\n",
    "#     os.mkdir(\"valid_face\")\n",
    "#     # create directory structure\n",
    "    \n",
    "#     for i in range(100):\n",
    "#         try:\n",
    "#             if i < 10:\n",
    "            \n",
    "#                 os.mkdir(\"valid_face/0\" + str(i))\n",
    "#             else:\n",
    "#                 os.mkdir(\"valid_face/\" + str(i))\n",
    "#         except FileExistsError:\n",
    "#             continue\n",
    "# except FileExistsError:\n",
    "#     print(\"valid_face Direcotry exist\")\n",
    "    \n",
    "# i = 0\n",
    "# dest_path = \"valid_face/\"+valid_data['full_path'].values\n",
    "# for p in x_valid_p:\n",
    "    \n",
    "#     copy2(p, dest_path[i])\n",
    "#     i += 1\n",
    "# #     print(\"train_face/\"+train_data['full_path'].values)\n",
    "# #     print(dest_path[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import sys\n",
    "import os\n",
    "import PIL\n",
    "# import the necessary packages\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tfÃ\n",
    "from keras.optimizers import *\n",
    "from keras.applications import Xception\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    " \n",
    "# import the necessary packages\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "# from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = Xception(input_shape=(96, 96, 3), \n",
    "#                               weights=None, include_top=False)\n",
    "# inputs = base_model.input\n",
    "# x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "# predictions = Dense(80, activation='softmax',name=\"ages_output\")(x)\n",
    "# model = Model(base_model.input,predictions)\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceNet:\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_ages_branch(inputs, numAges, finalAct=\"softmax\", chanDim=-1):\n",
    "        # utilize a lambda layer to convert the 3 channel input to a\n",
    "        # grayscale representation\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(inputs) \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        x = Flatten()(x)\n",
    "        predictions = Dense(numAges, activation=finalAct,name=\"ages_output\")(x)\n",
    "        # add your top layer block to your base model\n",
    "\n",
    "        #print(model.summary())\n",
    "    \n",
    "        # define a branch of output layers for the number of different\n",
    "        # ages\n",
    "        # return the category prediction sub-network\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_gender_branch(inputs, numGender, finalAct=\"softmax\", chanDim=-1):\n",
    "        \n",
    "        padding = \"same\"\n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=padding)(inputs) \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=padding)(x) \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(64, (5, 5), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Conv2D(64, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(64, (5, 5), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Conv2D(64, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    " \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(128, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Conv2D(128, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # define a branch of output layers for the number of different\n",
    "        # genders\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(numGender)(x)\n",
    "        x = Activation(finalAct, name=\"gender_output\")(x)\n",
    " \n",
    "        # return the color prediction sub-network\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(width, height, numAges, numGenders, finalAct=\"softmax\"):\n",
    "        # initialize the input shape and channel dimension (this code\n",
    "        # assumes you are using TensorFlow which utilizes channels\n",
    "        # last ordering)\n",
    "        inputShape = (height, width, 3)\n",
    "        chanDim = -1\n",
    "        #base_model = Xception(input_shape=inputShape, \n",
    "#                               weights=None, include_top=False)\n",
    "        #f#or layer in base_model.layers:\n",
    "         #   layer.trainable = \n",
    "        # construct both the \"category\" and \"color\" sub-networks\n",
    "        inputs = Input(shape=inputShape)\n",
    "        \n",
    "        agesBranch = FaceNet.build_ages_branch(inputs,\n",
    "            numAges, finalAct=finalAct, chanDim=chanDim)\n",
    "        for layer in agesBranch.layers:\n",
    "            layer.trainable = False\n",
    "        genderBranch = FaceNet.build_gender_branch(inputs,\n",
    "            numGenders, finalAct=finalAct, chanDim=chanDim)\n",
    " \n",
    "        # create the model using our input (the batch of images) and\n",
    "        # two separate outputs -- one for the clothing category\n",
    "        # branch and another for the color branch, respectively\n",
    "        model = Model(\n",
    "            inputs=inputs,\n",
    "            outputs=[agesBranch, genderBranch],\n",
    "            )\n",
    "        \n",
    "        print(model.summary())\n",
    "        plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed for reproducible results (only works on CPU, not GPU)\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "tf.set_random_seed(seed=seed)\n",
    "\n",
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 64\n",
    "IMAGE_DIMS = (96, 96, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create inputs\n",
    "\n",
    "# # train\n",
    "# # loop over the input images\n",
    "# train_x = []\n",
    "# for imagePath in x_train_p:\n",
    "#     # load the image, pre-process it, and store it in the data list\n",
    "#     image = cv2.imread(imagePath)\n",
    "#     image = img_to_array(image)\n",
    "#     train_x.append(image)\n",
    "    \n",
    "# # valid\n",
    "# # loop over the input images\n",
    "# valid_x = []\n",
    "# for imagePath in x_valid_p:\n",
    "#     # load the image, pre-process it, and store it in the data list\n",
    "#     image = cv2.imread(imagePath)\n",
    "#     image = img_to_array(image)\n",
    "#     valid_x.append(image)\n",
    " \n",
    "# print(\"train_x: {} | valid_x: {}\".format(len(train_x), len(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_gender = LabelBinarizer()\n",
    "lb_age = LabelBinarizer()\n",
    "\n",
    "y_train_gender = lb_gender.fit_transform(y_train_gender)\n",
    "y_train_age = lb_age.fit_transform(y_train_age)\n",
    "y_train_gender = [y_train_gender, 1-y_train_gender]\n",
    "\n",
    "y_valid_gender = lb_gender.transform(y_valid_gender)\n",
    "y_valid_age = lb_age.transform(y_valid_age)\n",
    "y_valid_gender = [y_valid_gender, 1-y_valid_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mate/develop/PycharmProjects/GeFace/faces_colored/27/nm0001427_rm684628736_1963-6-17_2005.jpg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path+x_valid_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 97)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train_age)[1:41].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\",\n",
    "#     brightness_range=(0.2,1.0),\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainImageLoader(files_x, y_train_age, y_train_gender, batch_size,L):\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            train_x = []\n",
    "            for file in files_x[batch_start:limit]:\n",
    "                image = cv2.imread(project_path+file)\n",
    "                image = img_to_array(image)\n",
    "                train_x.append(image)\n",
    "            train_x = np.array(train_x, dtype=\"float32\") / 255.0\n",
    "            train_y = y_train_age\n",
    "            \n",
    "            y_train_g = np.array(y_train_gender).squeeze().T[batch_start:limit]\n",
    "            \n",
    "            y_train_a = np.array(train_y)[batch_start:limit]\n",
    "        \n",
    "\n",
    "            yield (train_x,{\"ages_output\": y_train_a, \"gender_output\": y_train_g}) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validImageLoader(files_x, y_valid_age, y_valid_gender, batch_size,L):\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            valid_x = []\n",
    "            for file in files_x[batch_start:limit]:\n",
    "                image = cv2.imread(project_path+file)\n",
    "                image = img_to_array(image)\n",
    "                valid_x.append(image)\n",
    "            valid_x = np.array(valid_x, dtype=\"float32\") / 255.0\n",
    "            valid_y = y_valid_age\n",
    "            \n",
    "            y_valid_g = np.array(y_valid_gender).squeeze().T[batch_start:limit]\n",
    "            y_valid_a = np.array(valid_y)[batch_start:limit]\n",
    "        \n",
    "\n",
    "            yield (valid_x,{\"ages_output\": y_valid_a, \"gender_output\": y_valid_g}) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages number 97\n",
      "[INFO] compiling model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1731688df910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model = FaceNet.build(IMAGE_DIMS[0], IMAGE_DIMS[1], numAges=len(lb_age.classes_), \n\u001b[0;32m----> 6\u001b[0;31m                       numGenders=2,finalAct=\"softmax\")\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# create optimazitions method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINIT_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINIT_LR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e78ffddff2a4>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(width, height, numAges, numGenders, finalAct)\u001b[0m\n\u001b[1;32m    101\u001b[0m         agesBranch = FaceNet.build_ages_branch(inputs,\n\u001b[1;32m    102\u001b[0m             numAges, finalAct=finalAct, chanDim=chanDim)\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magesBranch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         genderBranch = FaceNet.build_gender_branch(inputs,\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"Ages number\", len(lb_age.classes_))\n",
    "print(\"[INFO] compiling model...\")\n",
    "# load model\n",
    "model = FaceNet.build(IMAGE_DIMS[0], IMAGE_DIMS[1], numAges=len(lb_age.classes_), \n",
    "                      numGenders=2,finalAct=\"softmax\")\n",
    "# create optimazitions method\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "#\tmetrics=[\"accuracy\"])\n",
    "losses = {\n",
    "\t\"ages_output\": \"categorical_crossentropy\",\n",
    "    \"gender_output\": \"categorical_crossentropy\"\n",
    "}\n",
    "lossWeights = {\"ages_output\": 1.0, \"gender_output\": 1.0}\n",
    "\n",
    "model.compile(loss=losses, optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# Create callback list for checkpoint and Earlystopping\n",
    "callbacks_list = [\n",
    "        ModelCheckpoint(project_path+\"gen_ages_model.hdf5\", monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=40, verbose=1)\n",
    "    ]\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "TBS = 64\n",
    "\n",
    "History = model.fit_generator(\n",
    " \ttrainImageLoader(x_train_p,y_train_age, y_train_gender,TBS,len(x_train_p)),\n",
    "    steps_per_epoch=len(x_train_p) // TBS,\n",
    "\tvalidation_data=validImageLoader(x_valid_p,y_valid_age,y_valid_gender,TBS,len(x_valid_p)),\n",
    "    validation_steps = len(x_valid_p) // TBS,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    "\t\n",
    ")\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(project_path+\"gen_ages_model.hdf5\")\n",
    " \n",
    "# save the category binarizer to disk\n",
    "print(\"[INFO] serializing category label binarizer...\")\n",
    "f = open(project_path+\"gen_ages.label\", \"wb\")\n",
    "f.write(pickle.dumps(lb_age))\n",
    "f.close()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_EPOCH = len(History.epoch)\n",
    "# print(y_train_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(History.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_names = [\"val_loss\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "(fig, ax) = plt.subplots(2, 1, figsize=(8,8))\n",
    "\n",
    "for (i, l) in enumerate(loss_names):\n",
    "    ax[i].set_title(\"Loss for {}\".format(l))\n",
    "    ax[i].set_xlabel(\"Epochs\")\n",
    "    ax[i].set_ylabel(\"Loss\")\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l], label=l)\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l],label=l)\n",
    "    ax[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"multi_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_names = [\"val_acc\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "(fig, ax) = plt.subplots(2, 1, figsize=(8,8))\n",
    "\n",
    "for (i, l) in enumerate(accuracy_names):\n",
    "    ax[i].set_title(\"Accuracy for {}\".format(l))\n",
    "    ax[i].set_xlabel(\"Epochs\")\n",
    "    ax[i].set_ylabel(\"Accuracy\")\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l], label=l)\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l],label=l)\n",
    "    ax[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"multi.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # create a new figure for the accuracies\n",
    "accuracyNames = [\"acc\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "(fig, ax) = plt.subplots(2, 1, figsize=(8, 8))\n",
    " \n",
    "# loop over the accuracy names\n",
    "for (i, l) in enumerate(accuracyNames):\n",
    "\t# plot the loss for both the training and validation data\n",
    "\tax[i].set_title(\"Accuracy for {}\".format(l))\n",
    "\tax[i].set_xlabel(\"Epoch #\")\n",
    "\tax[i].set_ylabel(\"Accuracy\")\n",
    "\tax[i].plot(np.arange(0, REAL_EPOCH), History.history[l], label=l)\n",
    "\tax[i].plot(np.arange(0, REAL_EPOCH), History.history[\"val_\" + l],\n",
    "\t\tlabel=\"val_\" + l)\n",
    "\tax[i].legend()\n",
    " \n",
    "# save the accuracies figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"multi_accs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the image\n",
    "image = cv2.imread(project_path+\"p_barbi.jpg\")\n",
    "#image = cv2.imread(project_path+\"faces_colored/01/nm0000001_rm124825600_1899-5-10_1968.jpg\")\n",
    "# image = cv2.imread(\"/home/mate/Pictures/dorka1.jpg\")\n",
    "face_cascade = cv2.CascadeClassifier('detector/haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "bb = []\n",
    "i = 0\n",
    "output = image.copy()\n",
    "for (x,y,w,h) in faces:\n",
    "    bb.append([w * h, i])\n",
    "    cv2.rectangle(output,(x,y),(x+w,y+h),(255,0,0),2)\n",
    " #   roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    i += 1\n",
    "    print(i)\n",
    "    break\n",
    "\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (96, 96))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# load the trained convolutional neural network from disk, followed\n",
    "# by the category and color label binarizers, respectively\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model(\"gen_ages_model.hdf5\", custom_objects={\"tf\": tf})\n",
    "agesLB = pickle.loads(open(\"gen_ages.label\", \"rb\").read())\n",
    " \n",
    "# classify the input image using Keras' multi-output functionality\n",
    "print(\"[INFO] classifying image...\")\n",
    "(agesProba ) = model.predict(image)\n",
    " \n",
    "# find indexes of both the category and color outputs with the\n",
    "# largest probabilities, then determine the corresponding class\n",
    "# labels\n",
    "agesIdx = agesProba[0].argmax()\n",
    "\n",
    "agesLabel = agesLB.classes_[agesIdx]\n",
    "\n",
    "# draw the category label and color label on the image\n",
    "agesText = \"age: {} ({:.2f}%)\".format(agesLabel,\n",
    "\tagesProba[0][agesIdx] * 100)\n",
    "\n",
    "\n",
    "cv2.putText(output, agesText, (10, 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t0.7, (0, 255, 0), 2)\n",
    "\n",
    "# display the predictions to the terminal as well\n",
    "print(\"[INFO] {}\".format(agesText))\n",
    "# show the probabilities for each of the individual labels\n",
    "output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "# show the output image\n",
    "# print(\"[INFO] {} years old\".format(label))\n",
    "plt.imshow(output,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History.model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
