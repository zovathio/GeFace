{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chdir. it depends on the platform\n",
    "if sys.platform == 'linux':\n",
    "    # if os is linux cd to\n",
    "    project_path = \"/home/mate/develop/PycharmProjects/GeFace/\"\n",
    "    NUMBER_OF_DATA = 1000\n",
    "elif sys.platform is 'windows':\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mate/develop/PycharmProjects/GeFace\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(os.getcwd())\n",
    "    # Open CSV with all informations\n",
    "    csv_file = pd.read_csv(\"faces_colored/faces_correct.csv\",delimiter = ',', encoding = \"ISO-8859-1\", engine='python')\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "except (FileNotFoundError):\n",
    "    print(\"CSV file not found\")\n",
    "    current_path = os.getcwd()\n",
    "    print(\"Current path is \" + current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr  age                                     full_path  gender\n",
       "0   0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg     1.0\n",
       "1   1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg     1.0\n",
       "2   2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg     1.0\n",
       "3   5   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg     0.0\n",
       "4   6   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = csv_file.drop(columns=[\"nr\"])\n",
    "df = csv_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 1.0 to m as male\n",
    "#         0.0 to f as female\n",
    "def mod(x):\n",
    "    if x == 1.0:\n",
    "        x = \"m\"\n",
    "    else:\n",
    "        x = \"f\"\n",
    "    return x\n",
    "\n",
    "df[\"gender\"] = df[\"gender\"].apply(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm124825600_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>01/nm0000001_rm3343756032_1899-5-10_1970.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>01/nm0000001_rm577153792_1899-5-10_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>02/nm0000002_rm1075631616_1924-9-16_1991.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>02/nm0000002_rm1346607872_1924-9-16_2004.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr  age                                     full_path gender\n",
       "0   0   69   01/nm0000001_rm124825600_1899-5-10_1968.jpg      m\n",
       "1   1   71  01/nm0000001_rm3343756032_1899-5-10_1970.jpg      m\n",
       "2   2   69   01/nm0000001_rm577153792_1899-5-10_1968.jpg      m\n",
       "3   5   67  02/nm0000002_rm1075631616_1924-9-16_1991.jpg      f\n",
       "4   6   80  02/nm0000002_rm1346607872_1924-9-16_2004.jpg      f"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for testing the network\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "proba_df = df.head(NUMBER_OF_DATA)\n",
    "\n",
    "# Randomize but always the same random numbers\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "# shuffle rows\n",
    "proba_df = shuffle(proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1083</td>\n",
       "      <td>33</td>\n",
       "      <td>62/nm0000062_rm360689664_1935-1-8_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1496</td>\n",
       "      <td>37</td>\n",
       "      <td>84/nm0000084_rm3788019968_1965-12-31_2002.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1501</td>\n",
       "      <td>37</td>\n",
       "      <td>84/nm0000084_rm3838351616_1965-12-31_2002.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1382</td>\n",
       "      <td>26</td>\n",
       "      <td>79/nm0000079_rm2756104448_1940-9-5_1966.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>807</td>\n",
       "      <td>57</td>\n",
       "      <td>56/nm0000056_rm1541314816_1925-1-26_1982.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nr  age                                      full_path gender\n",
       "521  1083   33     62/nm0000062_rm360689664_1935-1-8_1968.jpg      m\n",
       "737  1496   37  84/nm0000084_rm3788019968_1965-12-31_2002.jpg      f\n",
       "740  1501   37  84/nm0000084_rm3838351616_1965-12-31_2002.jpg      f\n",
       "660  1382   26    79/nm0000079_rm2756104448_1940-9-5_1966.jpg      f\n",
       "411   807   57   56/nm0000056_rm1541314816_1925-1-26_1982.jpg      m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 700 | valid: 200 | test: 100\n"
     ]
    }
   ],
   "source": [
    "# calculate test train valid data numbers\n",
    "test_num = int(np.floor(0.1 * proba_df.shape[0]))\n",
    "valid_num = int(np.floor(0.2 * proba_df.shape[0]))\n",
    "train_num = int(proba_df.shape[0] - test_num - valid_num)\n",
    "print(\"train: {} | valid: {} | test: {}\".format(train_num, valid_num, test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (700, 4) | valid: (200, 4) | test: (100, 4)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train valid and test data\n",
    "train_data = proba_df.iloc[0:train_num, :]\n",
    "\n",
    "valid_data = proba_df.iloc[train_num:train_num + valid_num, :]\n",
    "\n",
    "test_data = proba_df.iloc[ train_num+valid_num:, :]\n",
    "\n",
    "print(\"train: {} | valid: {} | test: {}\".format(train_data.shape, valid_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faces_colored/92/nm0000092_rm2154539520_1939-10-27_1975.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"faces_colored/\"\n",
    "x_train_p = image_path + train_data['full_path'].values\n",
    "x_valid_p = image_path + valid_data['full_path'].values\n",
    "x_test_p = image_path + test_data['full_path'].values\n",
    "\n",
    "# x_train_l = image_path + train_data['age'].values\n",
    "# x_valid_l = image_path + train_data['age'].values\n",
    "# x_test_l = image_path + train_data['age'].values\n",
    "\n",
    "x_test_p.shape\n",
    "x_test_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 700  |  200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([33, 37, 37, 26, 57, 26, 26, 27, 45, 41, 44, 66, 60, 45, 38, 45, 75,\n",
       "       45, 54, 30, 48, 39, 39, 47, 47, 58, 44, 50, 50, 31, 38, 60, 59, 31,\n",
       "       37, 35, 29, 49, 46, 85, 64, 47, 30, 45, 42, 80, 41, 62, 41, 65, 61,\n",
       "       48, 51, 70, 84, 67, 60, 50, 50, 57, 68, 29, 65, 40, 56, 29, 26, 45,\n",
       "       48, 47, 43, 35, 62, 47, 60, 60, 26, 29, 67, 75, 38, 63, 33, 48, 30,\n",
       "       57, 45, 27, 41, 64, 39, 53, 33, 40, 59, 64, 54, 52, 59, 40, 31, 59,\n",
       "       41, 49, 26, 60, 31, 44, 40, 46, 49, 57, 42, 36, 52, 37, 77, 44, 80,\n",
       "       59, 48, 42, 23, 75, 51, 62, 46, 41, 50, 60, 56, 44, 48, 43, 46, 32,\n",
       "       39, 40, 82, 39, 31, 43, 41, 80, 48, 38, 67, 48, 58, 32, 26, 52, 39,\n",
       "       42, 44, 74, 30, 59, 85, 48, 68, 54, 26, 26, 39, 26, 80, 34, 30, 30,\n",
       "       69, 46, 59, 37, 50, 70, 49, 49, 70, 26, 33, 26, 40, 30, 44, 40, 59,\n",
       "       39, 44, 42, 42, 62, 60, 35, 51, 47, 64, 40, 26, 66, 80, 80, 29, 34,\n",
       "       32, 56, 60, 48, 33, 43, 54, 78, 45, 40, 68, 64, 68, 80, 41, 23, 33,\n",
       "       41, 50, 31, 42, 69, 47, 59, 39, 86, 38, 45, 46, 70, 80, 50, 51, 44,\n",
       "       50, 32, 67, 35, 27, 60, 80, 38, 42, 66, 66, 80, 87, 47, 59, 46, 41,\n",
       "       32, 27, 51, 44, 80, 41, 70, 53, 48, 74, 42, 60, 40, 59, 40, 50, 59,\n",
       "       36, 63, 46, 67, 35, 61, 53, 68, 66, 61, 58, 68, 71, 31, 53, 59, 77,\n",
       "       44, 44, 64, 31, 74, 55, 74, 50, 77, 80, 63, 49, 41, 62, 57, 50, 44,\n",
       "       75, 70, 45, 53, 59, 76, 61, 23, 53, 73, 67, 59, 41, 53, 42, 87, 29,\n",
       "       59, 50, 27, 75, 50, 23, 44, 47, 30, 41, 59, 69, 68, 27, 54, 50, 46,\n",
       "       46, 49, 40, 70, 35, 41, 48, 48, 48, 41, 76, 31, 38, 48, 36, 70, 29,\n",
       "       42, 64, 94, 42, 63, 44, 53, 60, 80, 50, 50, 74, 51, 39, 31, 78, 41,\n",
       "       67, 49, 46, 39, 35, 58, 51, 53, 64, 58, 50, 42, 31, 70, 44, 50, 73,\n",
       "       29, 29, 38, 62, 32, 49, 41, 48, 46, 67, 74, 87, 78, 60, 29, 45, 68,\n",
       "       28, 27, 27, 46, 62, 76, 36, 23, 62, 62, 27, 51, 50, 31, 50, 31, 37,\n",
       "       46, 40, 54, 60, 75, 68, 53, 58, 43, 36, 50, 70, 37, 45, 70, 50, 31,\n",
       "       45, 26, 57, 46, 60, 70, 60, 26, 78, 45, 35, 71, 43, 60, 31, 26, 37,\n",
       "       57, 86, 44, 56, 50, 53, 44, 44, 61, 30, 43, 56, 48, 45, 70, 32, 47,\n",
       "       51, 41, 56, 64, 54, 66, 83, 35, 80, 31, 29, 64, 60, 31, 31, 55, 48,\n",
       "       38, 48, 92, 41, 56, 51, 51, 26, 78, 35, 51, 64, 41, 29, 39, 44, 37,\n",
       "       49, 84, 38, 82, 31, 50, 75, 85, 50, 81, 58, 66, 44, 68, 50, 48, 49,\n",
       "       34, 59, 70, 31, 48, 62, 68, 45, 44, 51, 66, 41, 51, 71, 33, 51, 50,\n",
       "       39, 44, 27, 36, 67, 54, 39, 46, 29, 32, 38, 48, 37, 58, 31, 68, 42,\n",
       "       48, 49, 28, 51, 41, 26, 36, 75, 46, 78, 62, 59, 28, 58, 41, 94, 69,\n",
       "       41, 33, 68, 83, 44, 78, 44, 41, 84, 60, 29, 88, 46, 62, 26, 41, 45,\n",
       "       43, 68, 55, 61, 37, 80, 54, 32, 49, 60, 46, 63, 52, 60, 56, 92, 29,\n",
       "       50, 23, 41, 55, 50, 27, 50, 31, 48, 70, 45, 42, 80, 27, 31, 50, 48,\n",
       "       27, 45, 46, 61, 41, 37, 50, 82, 31, 73, 37, 70, 65, 29, 44, 37, 69,\n",
       "       44, 44, 31, 60, 25, 44, 48, 27, 37, 36, 75, 46, 62, 41, 78, 70, 43,\n",
       "       41, 39, 73, 62, 44, 56, 57, 41, 68, 62, 26, 38, 29, 78, 47, 44, 45,\n",
       "       60, 60, 54, 84, 36, 67, 53, 26, 57, 36, 40, 31, 59, 41, 51, 51, 60,\n",
       "       68, 44, 63])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the ages\n",
    "y_train_age = train_data['age'].values\n",
    "y_valid_age = valid_data['age'].values\n",
    "y_test_age = test_data['age'].values\n",
    "\n",
    "print(\"age:\" ,len(y_train_age), \" | \", len(y_valid_age))\n",
    "y_train_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: 700  |  200\n"
     ]
    }
   ],
   "source": [
    "y_train_gender = train_data['gender'].values\n",
    "y_valid_gender = valid_data['gender'].values\n",
    "y_test_gender = test_data['gender'].values\n",
    "print(\"gender:\", len(y_train_gender), \" | \", len(y_valid_gender))\n",
    "\n",
    "# convert to string\n",
    "y_train_age = y_train_age.astype(\"str\")\n",
    "y_valid_age = y_valid_age.astype(\"str\")\n",
    "y_test_age = y_test_age.astype(\"str\")\n",
    "\n",
    "#concate them\n",
    "# y_train_gen_age = np.core.defchararray.add(y_train_age, y_train_gender)\n",
    "# y_valid_gen_age = np.core.defchararray.add(y_valid_age, y_valid_gender)\n",
    "# y_test_gen_age = np.core.defchararray.add(y_test_age, y_test_gender)\n",
    "\n",
    "# print(\"gen_age:\", len(y_train_gen_age), \" | \", len(y_valid_gen_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy train, valid, test data into a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>age</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1083</td>\n",
       "      <td>33</td>\n",
       "      <td>62/nm0000062_rm360689664_1935-1-8_1968.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1496</td>\n",
       "      <td>37</td>\n",
       "      <td>84/nm0000084_rm3788019968_1965-12-31_2002.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1501</td>\n",
       "      <td>37</td>\n",
       "      <td>84/nm0000084_rm3838351616_1965-12-31_2002.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1382</td>\n",
       "      <td>26</td>\n",
       "      <td>79/nm0000079_rm2756104448_1940-9-5_1966.jpg</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>807</td>\n",
       "      <td>57</td>\n",
       "      <td>56/nm0000056_rm1541314816_1925-1-26_1982.jpg</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nr  age                                      full_path gender\n",
       "521  1083   33     62/nm0000062_rm360689664_1935-1-8_1968.jpg      m\n",
       "737  1496   37  84/nm0000084_rm3788019968_1965-12-31_2002.jpg      f\n",
       "740  1501   37  84/nm0000084_rm3838351616_1965-12-31_2002.jpg      f\n",
       "660  1382   26    79/nm0000079_rm2756104448_1940-9-5_1966.jpg      f\n",
       "411   807   57   56/nm0000056_rm1541314816_1925-1-26_1982.jpg      m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from shutil import copyfile, copy2\n",
    "# try:\n",
    "#     os.mkdir(\"test_face\")\n",
    "# except FileExistsError:\n",
    "#     print(\"test_face Direcotry exist\")\n",
    "    \n",
    "# # training \n",
    "# try:\n",
    "#     os.mkdir(\"train_face\")\n",
    "#     # create directory structure\n",
    "    \n",
    "    \n",
    "# except FileExistsError:\n",
    "#     print(\"train_face Direcotry exist\")\n",
    "    \n",
    "# for i in range(100):\n",
    "#     try:\n",
    "#         if i < 10:\n",
    "        \n",
    "#             os.mkdir(\"train_face/0\" + str(i))\n",
    "#         else:\n",
    "#             os.mkdir(\"train_face/\" + str(i))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "# i = 0\n",
    "# dest_path = \"train_face/\"+train_data['full_path'].values\n",
    "# for p in x_train_p:\n",
    "    \n",
    "#     copy2(p, dest_path[i])\n",
    "#     i += 1\n",
    "# #     print(\"train_face/\"+train_data['full_path'].values)\n",
    "# #     print(dest_path[i])\n",
    "\n",
    "# # validation\n",
    "# try:\n",
    "#     os.mkdir(\"valid_face\")\n",
    "#     # create directory structure\n",
    "    \n",
    "#     for i in range(100):\n",
    "#         try:\n",
    "#             if i < 10:\n",
    "            \n",
    "#                 os.mkdir(\"valid_face/0\" + str(i))\n",
    "#             else:\n",
    "#                 os.mkdir(\"valid_face/\" + str(i))\n",
    "#         except FileExistsError:\n",
    "#             continue\n",
    "# except FileExistsError:\n",
    "#     print(\"valid_face Direcotry exist\")\n",
    "    \n",
    "# i = 0\n",
    "# dest_path = \"valid_face/\"+valid_data['full_path'].values\n",
    "# for p in x_valid_p:\n",
    "    \n",
    "#     copy2(p, dest_path[i])\n",
    "#     i += 1\n",
    "# #     print(\"train_face/\"+train_data['full_path'].values)\n",
    "# #     print(dest_path[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import sys\n",
    "import os\n",
    "import PIL\n",
    "# import the necessary packages\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tfÃ\n",
    "from keras.optimizers import *\n",
    "from keras.applications import Xception\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    " \n",
    "# import the necessary packages\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "# from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = Xception(input_shape=(96, 96, 3), \n",
    "#                               weights=None, include_top=False)\n",
    "# inputs = base_model.input\n",
    "# x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "# predictions = Dense(80, activation='softmax',name=\"ages_output\")(x)\n",
    "# model = Model(base_model.input,predictions)\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceNet:\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_ages_branch(inputs, numAges, finalAct=\"softmax\", chanDim=-1):\n",
    "        # utilize a lambda layer to convert the 3 channel input to a\n",
    "        # grayscale representation\n",
    "        x = inputs\n",
    "        x = Flatten()(x)\n",
    "        predictions = Dense(numAges, activation=finalAct,name=\"ages_output\")(x)\n",
    "\n",
    "        # add your top layer block to your base model\n",
    "\n",
    "        #print(model.summary())\n",
    "    \n",
    "        # define a branch of output layers for the number of different\n",
    "        # ages\n",
    "        # return the category prediction sub-network\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_gender_branch(inputs, numGender, finalAct=\"softmax\", chanDim=-1):\n",
    "        \n",
    "        padding = \"same\"\n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=padding)(inputs) \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # CONV => RELU => POOL\n",
    "        x = Conv2D(32, (3, 3), padding=padding)(x) \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(64, (5, 5), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Conv2D(64, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(64, (5, 5), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Conv2D(64, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    " \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        x = Conv2D(128, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Conv2D(128, (3, 3), padding=padding)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        # define a branch of output layers for the number of different\n",
    "        # genders\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(numGender)(x)\n",
    "        x = Activation(finalAct, name=\"gender_output\")(x)\n",
    " \n",
    "        # return the color prediction sub-network\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(width, height, numAges, numGenders, finalAct=\"softmax\"):\n",
    "        # initialize the input shape and channel dimension (this code\n",
    "        # assumes you are using TensorFlow which utilizes channels\n",
    "        # last ordering)\n",
    "        inputShape = (height, width, 3)\n",
    "        chanDim = -1\n",
    "        base_model = Xception(input_shape=inputShape, \n",
    "                              weights=None, include_top=False)\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "        # construct both the \"category\" and \"color\" sub-networks\n",
    "        inputs = base_model.input\n",
    "        \n",
    "        agesBranch = FaceNet.build_ages_branch(base_model.output,\n",
    "            numAges, finalAct=finalAct, chanDim=chanDim)\n",
    "        \n",
    "        genderBranch = FaceNet.build_gender_branch(inputs,\n",
    "            numGenders, finalAct=finalAct, chanDim=chanDim)\n",
    " \n",
    "        # create the model using our input (the batch of images) and\n",
    "        # two separate outputs -- one for the clothing category\n",
    "        # branch and another for the color branch, respectively\n",
    "        model = Model(\n",
    "            inputs=inputs,\n",
    "            outputs=[agesBranch, genderBranch],\n",
    "            )\n",
    "        print(model.summary())\n",
    "        plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed for reproducible results (only works on CPU, not GPU)\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "tf.set_random_seed(seed=seed)\n",
    "\n",
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 1\n",
    "INIT_LR = 1e-3\n",
    "BS = 64\n",
    "IMAGE_DIMS = (96, 96, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create inputs\n",
    "\n",
    "# # train\n",
    "# # loop over the input images\n",
    "# train_x = []\n",
    "# for imagePath in x_train_p:\n",
    "#     # load the image, pre-process it, and store it in the data list\n",
    "#     image = cv2.imread(imagePath)\n",
    "#     image = img_to_array(image)\n",
    "#     train_x.append(image)\n",
    "    \n",
    "# # valid\n",
    "# # loop over the input images\n",
    "# valid_x = []\n",
    "# for imagePath in x_valid_p:\n",
    "#     # load the image, pre-process it, and store it in the data list\n",
    "#     image = cv2.imread(imagePath)\n",
    "#     image = img_to_array(image)\n",
    "#     valid_x.append(image)\n",
    " \n",
    "# print(\"train_x: {} | valid_x: {}\".format(len(train_x), len(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] class labels:\n"
     ]
    }
   ],
   "source": [
    "lb_gender = LabelBinarizer()\n",
    "lb_age = LabelBinarizer()\n",
    "\n",
    "y_train_gender = lb_gender.fit_transform(y_train_gender)\n",
    "#y_train_gen_age = lb_age.fit_transform(y_train_gen_age)\n",
    "y_train_age = lb_age.fit_transform(y_train_age)\n",
    "y_train_gender = [y_train_gender, 1-y_train_gender]\n",
    "# print(y_train_gender)\n",
    "\n",
    "#y_train_gender = np.array(y_train_gender)\n",
    "#y_train_gen_age = np.array(y_train_gen_age)\n",
    "\n",
    "# print(train_y)\n",
    "#print(\"[INFO] train data matrix: {:.2f}MB\".format(\n",
    "#\ttrain_x.nbytes / (1024 * 1000.0)))\n",
    " \n",
    "# print(y_train_gender)\n",
    "# binarize the labels\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "#valid_x = np.array(valid_x, dtype=\"float\") / 255.0\n",
    "\n",
    "\n",
    "#y_valid_gen_age = np.array(y_valid_gen_age)\n",
    "\n",
    "#print(\"[INFO] valid data matrix: {:.2f}MB\".format(\n",
    "#\tvalid_x.nbytes / (1024 * 1000.0)))\n",
    " \n",
    "# binarize the labels\n",
    "print(\"[INFO] class labels:\")\n",
    "# mlb = MultiLabelBinarizer()\n",
    "y_valid_gender = lb_gender.transform(y_valid_gender)\n",
    "y_valid_age = lb_age.transform(y_valid_age)\n",
    "y_valid_gender = [y_valid_gender, 1-y_valid_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train_gender).squeeze().T[1:40].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\",\n",
    "#     brightness_range=(0.2,1.0),\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainImageLoader(files_x, y_train_age, y_train_gender, batch_size,L):\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            train_x = []\n",
    "            for file in files_x[batch_start:limit]:\n",
    "                image = cv2.imread(file)\n",
    "                image = img_to_array(image)\n",
    "                train_x.append(image)\n",
    "            train_x = np.array(train_x, dtype=\"float\") / 255.0\n",
    "            train_y = y_train_age[batch_start:limit]\n",
    "            \n",
    "            y_train_g = y_train_gender\n",
    "            y_train_g = np.array(y_train_g).squeeze().T[batch_start:limit]\n",
    "            y_train_age = np.array(train_y)\n",
    "        \n",
    "\n",
    "            yield (train_x,{\"ages_output\": y_train_age, \"gender_output\": y_train_g}) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validImageLoader(files_x, y_valid_age, y_valid_gender, batch_size,L):\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            valid_x = []\n",
    "            for file in files_x[batch_start:limit]:\n",
    "                image = cv2.imread(file)\n",
    "                image = img_to_array(image)\n",
    "                valid_x.append(image)\n",
    "            valid_x = np.array(valid_x, dtype=\"float\") / 255.0\n",
    "            valid_y = y_valid_age[batch_start:limit]\n",
    "            y_valid_g = y_valid_gender[batch_start:limit]\n",
    "            y_valid_g = np.array(y_valid_g).squeeze().T[batch_start:limit]\n",
    "            y_valid_age = np.array(valid_y)\n",
    "        \n",
    "\n",
    "            yield (valid_x,{\"ages_output\": y_valid_age, \"gender_output\": y_valid_g}) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages number 65\n",
      "[INFO] compiling model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 47, 47, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 47, 47, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 47, 47, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 45, 45, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 45, 45, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 45, 45, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 45, 45, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 45, 45, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 45, 45, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 45, 45, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 45, 45, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 23, 23, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 23, 23, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 23, 23, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 23, 23, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 23, 23, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 23, 23, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 23, 23, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 23, 23, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 23, 23, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 23, 23, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 12, 12, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 12, 12, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 12, 12, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 12, 12, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 12, 12, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 12, 12, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 12, 12, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 12, 12, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 6, 6, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 6, 6, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 6, 6, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 6, 6, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 6, 6, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 6, 6, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 6, 6, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 6, 6, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 6, 6, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 6, 6, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 6, 6, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 6, 6, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 6, 6, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 6, 6, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 6, 6, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 6, 6, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 6, 6, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 6, 6, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 6, 6, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 6, 6, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 6, 6, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 6, 6, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 6, 6, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 6, 6, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 6, 6, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 6, 6, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 6, 6, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 96, 96, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 6, 6, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 96, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 96, 96, 32)   128         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 6, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 32)   9248        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 6, 6, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10, 10, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 10, 10, 64)   51264       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 6, 6, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 10, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 10, 10, 64)   256         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 10, 10, 64)   36928       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 6, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 64)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 10, 10, 64)   256         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 64)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 5, 5, 64)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 6, 6, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 5, 5, 64)     102464      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 5, 5, 64)     0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5, 5, 64)     256         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 6, 6, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 5, 5, 64)     36928       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 6, 6, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 5, 5, 64)     0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 6, 6, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 5, 5, 64)     256         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 6, 6, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 6, 6, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2, 2, 64)     0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 6, 6, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 128)    73856       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 6, 6, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 2, 2, 128)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 6, 6, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2, 2, 128)    512         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 6, 6, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 128)    147584      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 6, 6, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 2, 2, 128)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 3, 3, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 3, 3, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2, 2, 128)    512         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 3, 3, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 3, 3, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1, 1, 128)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 3, 3, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 3, 3, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 3, 3, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 3, 3, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128)          512         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 3, 3, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 18432)        0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            258         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ages_output (Dense)             (None, 65)           1198145     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gender_output (Activation)      (None, 2)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,538,379\n",
      "Trainable params: 22,482,443\n",
      "Non-trainable params: 55,936\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,256,12,12] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node block3_pool/MaxPool}} = MaxPool[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/block3_sepconv2_bn/cond/Merge_grad/cond_grad\"], data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block3_sepconv2_bn/cond/Merge)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss/ages_output_loss/Mean_2/_2329}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_18881_loss/ages_output_loss/Mean_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d06af314a4cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m )\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/deeplearn_gpu/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,256,12,12] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node block3_pool/MaxPool}} = MaxPool[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/block3_sepconv2_bn/cond/Merge_grad/cond_grad\"], data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block3_sepconv2_bn/cond/Merge)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss/ages_output_loss/Mean_2/_2329}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_18881_loss/ages_output_loss/Mean_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"Ages number\", len(lb_age.classes_))\n",
    "print(\"[INFO] compiling model...\")\n",
    "# load model\n",
    "model = FaceNet.build(IMAGE_DIMS[0], IMAGE_DIMS[1], numAges=len(lb_age.classes_), \n",
    "                      numGenders=2,finalAct=\"softmax\")\n",
    "# create optimazitions method\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "#\tmetrics=[\"accuracy\"])\n",
    "losses = {\n",
    "\t\"ages_output\": \"categorical_crossentropy\",\n",
    "    \"gender_output\": \"categorical_crossentropy\"\n",
    "}\n",
    "lossWeights = {\"ages_output\": 1.0, \"gender_output\": 1.0}\n",
    "\n",
    "model.compile(loss=losses, optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# Create callback list for checkpoint and Earlystopping\n",
    "callbacks_list = [\n",
    "        ModelCheckpoint(project_path+\"gen_ages_model.hdf5\", monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=40, verbose=1)\n",
    "    ]\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "\n",
    "History = model.fit_generator(\n",
    " \ttrainImageLoader(x_train_p,y_train_age, y_train_gender,32,len(x_train_p)),\n",
    "    steps_per_epoch=len(x_train_p) // 32,\n",
    "\tvalidation_data=validImageLoader(x_valid_p,y_valid_age,y_valid_gender,32,len(x_valid_p)),\n",
    "    validation_steps = len(x_valid_p) // 32,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    "\t\n",
    ")\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(project_path+\"gen_ages_model.hdf5\")\n",
    " \n",
    "# save the category binarizer to disk\n",
    "print(\"[INFO] serializing category label binarizer...\")\n",
    "f = open(project_path+\"gen_ages.label\", \"wb\")\n",
    "f.write(pickle.dumps(lb_age))\n",
    "f.close()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_EPOCH = len(History.epoch)\n",
    "# print(y_train_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(History.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_names = [\"val_loss\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "(fig, ax) = plt.subplots(2, 1, figsize=(8,8))\n",
    "\n",
    "for (i, l) in enumerate(loss_names):\n",
    "    ax[i].set_title(\"Loss for {}\".format(l))\n",
    "    ax[i].set_xlabel(\"Epochs\")\n",
    "    ax[i].set_ylabel(\"Loss\")\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l], label=l)\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l],label=l)\n",
    "    ax[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"multi_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_names = [\"val_acc\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "(fig, ax) = plt.subplots(2, 1, figsize=(8,8))\n",
    "\n",
    "for (i, l) in enumerate(accuracy_names):\n",
    "    ax[i].set_title(\"Accuracy for {}\".format(l))\n",
    "    ax[i].set_xlabel(\"Epochs\")\n",
    "    ax[i].set_ylabel(\"Accuracy\")\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l], label=l)\n",
    "    ax[i].plot(np.arange(0, REAL_EPOCH), History.history[l],label=l)\n",
    "    ax[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"multi.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # create a new figure for the accuracies\n",
    "accuracyNames = [\"acc\"]\n",
    "plt.style.use(\"ggplot\")\n",
    "(fig, ax) = plt.subplots(2, 1, figsize=(8, 8))\n",
    " \n",
    "# loop over the accuracy names\n",
    "for (i, l) in enumerate(accuracyNames):\n",
    "\t# plot the loss for both the training and validation data\n",
    "\tax[i].set_title(\"Accuracy for {}\".format(l))\n",
    "\tax[i].set_xlabel(\"Epoch #\")\n",
    "\tax[i].set_ylabel(\"Accuracy\")\n",
    "\tax[i].plot(np.arange(0, REAL_EPOCH), History.history[l], label=l)\n",
    "\tax[i].plot(np.arange(0, REAL_EPOCH), History.history[\"val_\" + l],\n",
    "\t\tlabel=\"val_\" + l)\n",
    "\tax[i].legend()\n",
    " \n",
    "# save the accuracies figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"multi_accs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the image\n",
    "image = cv2.imread(project_path+\"p_barbi.jpg\")\n",
    "#image = cv2.imread(project_path+\"faces_colored/01/nm0000001_rm124825600_1899-5-10_1968.jpg\")\n",
    "# image = cv2.imread(\"/home/mate/Pictures/dorka1.jpg\")\n",
    "face_cascade = cv2.CascadeClassifier('detector/haarcascade_frontalface_default.xml')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "bb = []\n",
    "i = 0\n",
    "output = image.copy()\n",
    "for (x,y,w,h) in faces:\n",
    "    bb.append([w * h, i])\n",
    "    cv2.rectangle(output,(x,y),(x+w,y+h),(255,0,0),2)\n",
    " #   roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    i += 1\n",
    "    print(i)\n",
    "    break\n",
    "\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (96, 96))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# load the trained convolutional neural network from disk, followed\n",
    "# by the category and color label binarizers, respectively\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model(\"gen_ages_model.hdf5\", custom_objects={\"tf\": tf})\n",
    "agesLB = pickle.loads(open(\"gen_ages.label\", \"rb\").read())\n",
    " \n",
    "# classify the input image using Keras' multi-output functionality\n",
    "print(\"[INFO] classifying image...\")\n",
    "(agesProba ) = model.predict(image)\n",
    " \n",
    "# find indexes of both the category and color outputs with the\n",
    "# largest probabilities, then determine the corresponding class\n",
    "# labels\n",
    "agesIdx = agesProba[0].argmax()\n",
    "\n",
    "agesLabel = agesLB.classes_[agesIdx]\n",
    "\n",
    "# draw the category label and color label on the image\n",
    "agesText = \"age: {} ({:.2f}%)\".format(agesLabel,\n",
    "\tagesProba[0][agesIdx] * 100)\n",
    "\n",
    "\n",
    "cv2.putText(output, agesText, (10, 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t0.7, (0, 255, 0), 2)\n",
    "\n",
    "# display the predictions to the terminal as well\n",
    "print(\"[INFO] {}\".format(agesText))\n",
    "# show the probabilities for each of the individual labels\n",
    "output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "# show the output image\n",
    "# print(\"[INFO] {} years old\".format(label))\n",
    "plt.imshow(output,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History.model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
